{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f62945d-82e6-481c-9b94-786e931638b5",
   "metadata": {},
   "source": [
    "## HOME WORK-02\n",
    "NAME :Bhuma Poorna Sasi Lakshmi Sai Sree\n",
    "\n",
    "\n",
    "Question-01\n",
    "\n",
    "Now we import some of the libraries usually needed by our workload.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49b98d-8c27-4efc-8504-830a86ea5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb1792e-cdb2-408a-95ad-226a2f27a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801915e9-c7a2-46f0-b987-bdddb6f46034",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "In this step, rather than downloading a file from Google Drive, we will load a famous machine learning dataset, the Breast Cancer Wisconsin dataset, using the scikit-learn datasets loader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4c4a5-5e4d-4fe7-90bf-ebe91c22bd57",
   "metadata": {},
   "source": [
    "For convenience, given that the dataset is small, we first\n",
    "\n",
    "construct a Pandas dataframe\n",
    "tune the schema\n",
    "and convert it into a Spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d1650c-b8ad-4f8a-b9e3-0b0d3b3a1fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "pd_df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "df = spark.createDataFrame(pd_df)\n",
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287ae107-7780-4e1b-9e76-f8fef3974bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mean radius: double (nullable = true)\n",
      " |-- mean texture: double (nullable = true)\n",
      " |-- mean perimeter: double (nullable = true)\n",
      " |-- mean area: double (nullable = true)\n",
      " |-- mean smoothness: double (nullable = true)\n",
      " |-- mean compactness: double (nullable = true)\n",
      " |-- mean concavity: double (nullable = true)\n",
      " |-- mean concave points: double (nullable = true)\n",
      " |-- mean symmetry: double (nullable = true)\n",
      " |-- mean fractal dimension: double (nullable = true)\n",
      " |-- radius error: double (nullable = true)\n",
      " |-- texture error: double (nullable = true)\n",
      " |-- perimeter error: double (nullable = true)\n",
      " |-- area error: double (nullable = true)\n",
      " |-- smoothness error: double (nullable = true)\n",
      " |-- compactness error: double (nullable = true)\n",
      " |-- concavity error: double (nullable = true)\n",
      " |-- concave points error: double (nullable = true)\n",
      " |-- symmetry error: double (nullable = true)\n",
      " |-- fractal dimension error: double (nullable = true)\n",
      " |-- worst radius: double (nullable = true)\n",
      " |-- worst texture: double (nullable = true)\n",
      " |-- worst perimeter: double (nullable = true)\n",
      " |-- worst area: double (nullable = true)\n",
      " |-- worst smoothness: double (nullable = true)\n",
      " |-- worst compactness: double (nullable = true)\n",
      " |-- worst concavity: double (nullable = true)\n",
      " |-- worst concave points: double (nullable = true)\n",
      " |-- worst symmetry: double (nullable = true)\n",
      " |-- worst fractal dimension: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b318f2-999d-4d67-beca-e7961da070e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cust=df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6513f73a-8a39-433c-a0bb-d19c213750ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mean radius: double (nullable = true)\n",
      " |-- mean texture: double (nullable = true)\n",
      " |-- mean perimeter: double (nullable = true)\n",
      " |-- mean area: double (nullable = true)\n",
      " |-- mean smoothness: double (nullable = true)\n",
      " |-- mean compactness: double (nullable = true)\n",
      " |-- mean concavity: double (nullable = true)\n",
      " |-- mean concave points: double (nullable = true)\n",
      " |-- mean symmetry: double (nullable = true)\n",
      " |-- mean fractal dimension: double (nullable = true)\n",
      " |-- radius error: double (nullable = true)\n",
      " |-- texture error: double (nullable = true)\n",
      " |-- perimeter error: double (nullable = true)\n",
      " |-- area error: double (nullable = true)\n",
      " |-- smoothness error: double (nullable = true)\n",
      " |-- compactness error: double (nullable = true)\n",
      " |-- concavity error: double (nullable = true)\n",
      " |-- concave points error: double (nullable = true)\n",
      " |-- symmetry error: double (nullable = true)\n",
      " |-- fractal dimension error: double (nullable = true)\n",
      " |-- worst radius: double (nullable = true)\n",
      " |-- worst texture: double (nullable = true)\n",
      " |-- worst perimeter: double (nullable = true)\n",
      " |-- worst area: double (nullable = true)\n",
      " |-- worst smoothness: double (nullable = true)\n",
      " |-- worst compactness: double (nullable = true)\n",
      " |-- worst concavity: double (nullable = true)\n",
      " |-- worst concave points: double (nullable = true)\n",
      " |-- worst symmetry: double (nullable = true)\n",
      " |-- worst fractal dimension: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_cust.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03079706-bb5c-46ad-93b6-e8d95aaad2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_columns_null(spark, df, column_list, nullable=False):\n",
    "    \n",
    "    for struct in df.schema:\n",
    "        \n",
    "        if struct.name in column_list:\n",
    "            \n",
    "            struct.nullable = nullable\n",
    "    df_mod = spark.createDataFrame(df.rdd, df.schema)\n",
    "    return df_mod\n",
    "\n",
    "df = make_df_columns_null(spark, df, df.columns)\n",
    "df = df.withColumn('features', array(df.columns))\n",
    "vectors = df.rdd.map(lambda row: Vectors.dense(row.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473a3e1d-bf0c-47b3-8d48-51a3d08e6534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mean radius: double (nullable = false)\n",
      " |-- mean texture: double (nullable = false)\n",
      " |-- mean perimeter: double (nullable = false)\n",
      " |-- mean area: double (nullable = false)\n",
      " |-- mean smoothness: double (nullable = false)\n",
      " |-- mean compactness: double (nullable = false)\n",
      " |-- mean concavity: double (nullable = false)\n",
      " |-- mean concave points: double (nullable = false)\n",
      " |-- mean symmetry: double (nullable = false)\n",
      " |-- mean fractal dimension: double (nullable = false)\n",
      " |-- radius error: double (nullable = false)\n",
      " |-- texture error: double (nullable = false)\n",
      " |-- perimeter error: double (nullable = false)\n",
      " |-- area error: double (nullable = false)\n",
      " |-- smoothness error: double (nullable = false)\n",
      " |-- compactness error: double (nullable = false)\n",
      " |-- concavity error: double (nullable = false)\n",
      " |-- concave points error: double (nullable = false)\n",
      " |-- symmetry error: double (nullable = false)\n",
      " |-- fractal dimension error: double (nullable = false)\n",
      " |-- worst radius: double (nullable = false)\n",
      " |-- worst texture: double (nullable = false)\n",
      " |-- worst perimeter: double (nullable = false)\n",
      " |-- worst area: double (nullable = false)\n",
      " |-- worst smoothness: double (nullable = false)\n",
      " |-- worst compactness: double (nullable = false)\n",
      " |-- worst concavity: double (nullable = false)\n",
      " |-- worst concave points: double (nullable = false)\n",
      " |-- worst symmetry: double (nullable = false)\n",
      " |-- worst fractal dimension: double (nullable = false)\n",
      " |-- features: array (nullable = false)\n",
      " |    |-- element: double (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8992123c-b367-44e9-8beb-ee209a1e7772",
   "metadata": {},
   "source": [
    "With the next cell, we build the two data structures that we will be using throughout this file:\n",
    "\n",
    "features, a dataframe of Dense vectors, containing all the original features in the dataset;\n",
    "labels, a series of binary labels indicating if the corresponding set of features belongs to a subject with breast cancer, or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8746879a-6530-44ed-a552-a23ab7611713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "features = spark.createDataFrame(vectors.map(Row), [\"features\"])\n",
    "labels = pd.Series(breast_cancer.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede45ec3-5ea4-41e1-85fc-688dfbd6fae6",
   "metadata": {},
   "source": [
    "## Your task\n",
    "If you run successfully the Setup and Data Preprocessing stages, you are now ready to cluster the data with the K-means algorithm included in MLlib (Spark's Machine Learning library). Set the k parameter to 2, fit the model, and the compute the Silhouette score (i.e., a measure of quality of the obtained clustering).\n",
    "\n",
    "IMPORTANT: use the MLlib implementation of the Silhouette score (via ClusteringEvaluator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb756f7-7304-4717-bb6a-892c7f19888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317f6b42-0b92-45df-bb78-d389f7ac1f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "# Trains a k-means model.\n",
    "kmeans_model = KMeans().setK(2).setSeed(1)\n",
    "model_fit = kmeans_model.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1624b641-aa6a-4e49-8751-d2f0cb6b9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions_kmeans = model_fit.transform(features)\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator_kmeans = ClusteringEvaluator()\n",
    "silhouette_kmeans = evaluator_kmeans.evaluate(predictions_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91506a97-f8be-4acb-a80b-306cb650902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette: 0.8342904262826143\n"
     ]
    }
   ],
   "source": [
    "print(f'Silhouette: {silhouette_kmeans}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d667c73-6d82-4f50-a366-2eb15eafebfe",
   "metadata": {},
   "source": [
    "Take the predictions produced by K-means, and compare them with the labels variable (i.e., the ground truth from our dataset).\n",
    "\n",
    "Compute how many data points in the dataset have been clustered correctly (i.e., positive cases in one cluster, negative cases in the other).\n",
    "\n",
    "HINT: you can use np.count_nonzero(series_a == series_b) to quickly compute the element-wise comparison of two series.\n",
    "\n",
    "IMPORTANT: K-means is a clustering algorithm, so it will not output a label for each data point, but just a cluster identifier! As such, label 0 does not necessarily match the cluster identifier 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f167105-b7d4-4711-b0af-aa49efd90204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_needed = predictions_kmeans.toPandas()\n",
    "converted_result = predictions_needed['prediction'].apply(lambda x: 0 if x else 1)\n",
    "np.count_nonzero(converted_result.values == labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7e30f-9191-46f8-8444-37c2d3e738db",
   "metadata": {},
   "source": [
    "Now perform dimensionality reduction on the features using the PCA statistical procedure, available as well in MLlib.\n",
    "\n",
    "Set the k parameter to 2, effectively reducing the dataset size of a 15X factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56bf277f-da3e-41e7-a148-e4f41a5ecabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|pca                                     |\n",
      "+----------------------------------------+\n",
      "|[-2260.013886292541,-187.96030122263645]|\n",
      "|[-2368.9937557820544,121.5874242581556] |\n",
      "|[-2095.665201547861,145.11398565870158] |\n",
      "|[-692.6905100570509,38.57692259208186]  |\n",
      "|[-2030.2124927427062,295.2979839927929] |\n",
      "|[-888.2800535760762,26.079796157025843] |\n",
      "|[-1921.0822124748452,58.80757247309972] |\n",
      "|[-1074.7813350047961,31.771227808469845]|\n",
      "|[-908.5784781618831,63.83075279044658]  |\n",
      "|[-861.578449407568,40.57073549705342]   |\n",
      "|[-1404.5591306499473,88.2321825773626]  |\n",
      "|[-1524.2324408687819,-3.263057316777707]|\n",
      "|[-1734.3856477464153,273.16267815114634]|\n",
      "|[-1162.9140032230357,217.63481808344636]|\n",
      "|[-903.4301030498834,135.6151766608481]  |\n",
      "|[-1155.875995420685,76.80889383742188]  |\n",
      "|[-1335.729432130807,-2.468400545035389] |\n",
      "|[-1547.264092252309,3.805675972574695]  |\n",
      "|[-2714.964765181216,-164.3761086425877] |\n",
      "|[-908.2502671870876,118.2164200822313]  |\n",
      "+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "pca_model = PCA(k=2, inputCol=\"features\", outputCol=\"pca\")\n",
    "model_pca = pca_model.fit(features)\n",
    "result = model_pca.transform(features).select(\"pca\")\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6cd3a0-fa55-418e-aa41-ed0d2368041c",
   "metadata": {},
   "source": [
    "Now run K-means with the same parameters as above, but on the pcaFeatures produced by the PCA reduction you just executed.\n",
    "\n",
    "Compute the Silhouette score, as well as the number of data points that have been clustered correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aca10919-864b-47dd-9dec-6753eac4eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette of PCA 0.8348610363444832\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(featuresCol='pca').setK(2).setSeed(1)\n",
    "model_final = kmeans.fit(result)\n",
    "pca_predictions_final = model_final.transform(result)\n",
    "pca_evaluator_final = ClusteringEvaluator(featuresCol='pca')\n",
    "pca_silhouette = pca_evaluator_final.evaluate(pca_predictions_final)\n",
    "print(f'Silhouette of PCA {pca_silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "561bc498-aaf8-4ce8-a4c3-7172882fd347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_output = pca_predictions_final.toPandas()\n",
    "converted_pca = pca_output['prediction'].apply(lambda x: 0 if x else 1)\n",
    "np.count_nonzero(converted_pca == labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b50714b-e569-4f60-b961-56c020f43396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopping Spark environment\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8e214-e01a-43f9-af6f-4750b055976c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
